# Text_summ_BERT

Text summarization using SOTA models

Text Summarization is the process of shortening a set of data computationally, to create a subset (a summary) that represents the most important or relevant information within the original content.- Wikipedia

Text summarization methods can be grouped into two main categories: Extractive and Abstractive methods.

Extractive Text Summarization
The traditional method with the main objective to identify the significant sentences of the text and add them to the summary. Note that the summary obtained contains exact sentences from the original text data.


Abstractive Text Summarization
The advanced method, with the approach to identify the important sections, interpret the context and reproduce the text in a new way. This ensures that the core information is conveyed through the shortest text possible. Note that here, the sentences, in summary, are generated by the model, not just extracted from the original text data.

Text Summarization with BERT :-
It is a pre-trained model that is naturally bidirectional. This pre-trained model can be tuned to easily perform the NLP tasks as specified, Summarization in our case.


Getting Started :-

pip install -r requirements.txt

python app.py

Jupyter notebook :-
Run text_summry.ipynb


